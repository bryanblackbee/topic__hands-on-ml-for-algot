# 14. Topic Modelling

## Learning topics: goals & approaches
Topic modelling aims to discover hidden topics or themes across documents that capture semantic information beyond individual words. It goes beyond lexical analysis which only analyses words, towards semantic analysis which infers the writer's intent. In other words, topic modelling is used to summarise large collections of documents to facilitate organisation, management and search and recommendations. They aim to address the curse of dimensionality that plague the BoW model. Furthermore, it addresses the polysematic problem that the BoW model cannot capture.

We move beyond linear algebra to hierarchical probabilistic models for this type of problem. It assumes that there is an explicit document generation process and provide algorithms to reverse engineer this process to recover the underlying topics.

The key models for discussion in this chapter are:

|Model|Description|
|-|:--|
|Latent Semantic Indexing (LSI)|Reduce the word space dimensionality to capture semantic document-term relationships|
|Probabilistic Latent Semantic Analysis (pLSA)|Reverse-engineer a process that assumes words generate a topic and documents are a mix of topics|
|Latent Dirichlet Allocation (LDA)|Adds a generative process for documents: a three-level hierarchical Bayesian model|

## Latent semantic indexing

## Probabilistic latent semantic analysis

## Latent Dirichlet allocation
